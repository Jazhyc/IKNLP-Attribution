{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: outlines in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: jsonschema in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (4.23.0)\n",
      "Requirement already satisfied: tqdm in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (4.67.1)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (0.1.26)\n",
      "Requirement already satisfied: genson in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (1.3.0)\n",
      "Requirement already satisfied: nest_asyncio in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (1.6.0)\n",
      "Requirement already satisfied: iso3166 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (2.1.1)\n",
      "Requirement already satisfied: typing_extensions in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (4.12.2)\n",
      "Requirement already satisfied: numpy in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (1.26.4)\n",
      "Requirement already satisfied: referencing in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (0.36.2)\n",
      "Requirement already satisfied: torch in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (2.6.0)\n",
      "Requirement already satisfied: interegular in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (0.3.3)\n",
      "Requirement already satisfied: pre-commit>=4.0.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (4.2.0)\n",
      "Requirement already satisfied: airportsdata in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (20250224)\n",
      "Requirement already satisfied: requests in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (2.32.3)\n",
      "Requirement already satisfied: lark in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (1.2.2)\n",
      "Requirement already satisfied: jinja2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (3.1.6)\n",
      "Requirement already satisfied: cloudpickle in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (3.1.1)\n",
      "Requirement already satisfied: diskcache in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (5.6.3)\n",
      "Requirement already satisfied: pydantic>=2.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from outlines) (2.10.6)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (6.0.2)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (20.29.3)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (2.6.9)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pydantic>=2.0->outlines) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pydantic>=2.0->outlines) (0.7.0)\n",
      "Requirement already satisfied: filelock<4,>=3.12.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (3.18.0)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (4.2.2)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (0.3.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from jinja2->outlines) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from jsonschema->outlines) (25.3.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from jsonschema->outlines) (0.23.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from jsonschema->outlines) (2024.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from requests->outlines) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from requests->outlines) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from requests->outlines) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from requests->outlines) (2025.1.31)\n",
      "Requirement already satisfied: fsspec in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from torch->outlines) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from torch->outlines) (1.13.1)\n",
      "Requirement already satisfied: networkx in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from torch->outlines) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from sympy==1.13.1->torch->outlines) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from tqdm->outlines) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'E:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: context_cite in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: pandas in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (2.2.2)\n",
      "Requirement already satisfied: nltk>=3.8.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (3.9.1)\n",
      "Requirement already satisfied: torch in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (2.6.0)\n",
      "Requirement already satisfied: tqdm in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (4.67.1)\n",
      "Requirement already satisfied: numpy in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (1.26.4)\n",
      "Requirement already satisfied: transformers in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (4.50.0)\n",
      "Requirement already satisfied: spacy in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (3.8.4)\n",
      "Requirement already satisfied: datasets in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (3.4.1)\n",
      "Requirement already satisfied: scikit-learn in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from context_cite) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from nltk>=3.8.2->context_cite) (2024.11.6)\n",
      "Requirement already satisfied: joblib in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from nltk>=3.8.2->context_cite) (1.4.2)\n",
      "Requirement already satisfied: click in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from nltk>=3.8.2->context_cite) (8.1.8)\n",
      "Requirement already satisfied: colorama in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from click->nltk>=3.8.2->context_cite) (0.4.6)\n",
      "Requirement already satisfied: requests>=2.32.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (2.32.3)\n",
      "Requirement already satisfied: packaging in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (6.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (0.3.8)\n",
      "Requirement already satisfied: xxhash in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (3.11.14)\n",
      "Requirement already satisfied: filelock in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (3.18.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (0.29.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from datasets->context_cite) (19.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.18.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from aiohttp->datasets->context_cite) (6.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from aiohttp->datasets->context_cite) (25.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from aiohttp->datasets->context_cite) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from aiohttp->datasets->context_cite) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from aiohttp->datasets->context_cite) (0.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets->context_cite) (4.12.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from requests>=2.32.2->datasets->context_cite) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from requests>=2.32.2->datasets->context_cite) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from requests>=2.32.2->datasets->context_cite) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from requests>=2.32.2->datasets->context_cite) (3.10)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pandas->context_cite) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pandas->context_cite) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pandas->context_cite) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->context_cite) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from scikit-learn->context_cite) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from scikit-learn->context_cite) (1.13.1)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (2.0.11)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (3.0.9)\n",
      "Requirement already satisfied: setuptools in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (57.4.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (1.1.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (3.5.0)\n",
      "Requirement already satisfied: jinja2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (3.1.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (3.0.12)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (0.15.2)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (8.3.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (2.5.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (1.0.12)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from spacy->context_cite) (2.10.6)\n",
      "Requirement already satisfied: language-data>=1.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->context_cite) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->context_cite) (1.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->context_cite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->context_cite) (2.27.2)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->context_cite) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy->context_cite) (0.1.5)\n",
      "Requirement already satisfied: rich>=10.11.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->context_cite) (13.9.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->context_cite) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (0.1.2)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->context_cite) (7.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->context_cite) (0.21.0)\n",
      "Requirement already satisfied: wrapt in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->context_cite) (1.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from jinja2->spacy->context_cite) (3.0.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from torch->context_cite) (1.13.1)\n",
      "Requirement already satisfied: networkx in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from torch->context_cite) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from sympy==1.13.1->torch->context_cite) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from transformers->context_cite) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages (from transformers->context_cite) (0.5.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'E:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install outlines\n",
    "!pip install context_cite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add the path to the parent directory to sys\n",
    "import sys, os\n",
    "\n",
    "# If current directory is called 'notebooks', chdir to the parent\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('../')\n",
    "    \n",
    "sys.path.append('attribution')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from constants import ModelNames, DatasetNames, LANGUAGE_MAPPING\n",
    "from model_utils import Model \n",
    "from dataset_utils import GSMDataset, PaddingCollator, is_correct_gsm, extract_answer_gsm\n",
    "from context_cite import ContextCiter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Necessary Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_dataset():\n",
    "    model = Model(ModelNames.QwenInstruct)\n",
    "    \n",
    "    return model, DatasetNames.MGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Processing Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseProcessing():\n",
    "    def __init__(self, model, dataset):\n",
    "        self.df_column_names = [\"question\", \"actual_answer\", \"model_gen_steps\", \"model_gen_answer\" ]\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def convert_dashes_incremental_steps_list(self, step):\n",
    "        furnished_steps = []\n",
    "\n",
    "        i = 1\n",
    "        for _, step in enumerate(steps[1:]):\n",
    "            if step:  # Skip empty parts (if any)\n",
    "                furnished_steps.append(str(i) + \". \" + step )  # Replace with number (1, 2, 3...)\n",
    "                i += 1\n",
    "        \n",
    "        return furnished_steps\n",
    "\n",
    "    def convert_dashes_incremental_steps(self, step):\n",
    "\n",
    "        '''\n",
    "        Returns str\n",
    "        '''\n",
    "\n",
    "        furnished_steps = self.convert_dashes_incremental_steps_list(step)\n",
    "\n",
    "        final_str = \"Step-by-Step Answer:\\n\"\n",
    "\n",
    "        final_str += \"\".join(furnished_steps)\n",
    "\n",
    "        return final_str\n",
    "\n",
    "\n",
    "    def process_model_responses_for_analysis(self):\n",
    "\n",
    "        mgsm_test = GSMDataset(self.dataset, self.model.tokenizer, instructions='', split='test', config='en')\n",
    "\n",
    "        mgsm_generation_df = pd.read_csv('results\\mgsm_en_Qwen2.5-1.5B-Instruct_results.csv')\n",
    "        mgsm_generations = mgsm_generation_df['response'].tolist()\n",
    "\n",
    "        all_steps = []\n",
    "        all_gen_final_ans = []\n",
    "\n",
    "        for response in mgsm_generations:\n",
    "            \n",
    "            steps = response.split(\"\\n-\")\n",
    "            final_step = steps[-1].split(\".\\r\\n\")[0]\n",
    "            steps.pop()\n",
    "            steps.append( final_step )\n",
    "\n",
    "            steps_str = self.convert_dashes_incremental_steps(steps)\n",
    "            all_steps.append( steps_str )\n",
    "\n",
    "            gen_final_ans = extract_answer_gsm(response)\n",
    "            all_gen_final_ans.append( gen_final_ans )\n",
    "\n",
    "        question_list = mgsm_test.dataset['question']\n",
    "        actual_answer = mgsm_test.dataset['answer_number']\n",
    "\n",
    "        percentile_list = pd.DataFrame(data=zip(question_list,actual_answer,all_steps, all_gen_final_ans), columns=self.df_column_names)\n",
    "\n",
    "        percentile_list.to_csv(\"results/analysis_mgsm_en_Qwen2.5-1.5B-Instruct_results.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     model, dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     responseProcessing \u001b[38;5;241m=\u001b[39m ResponseProcessing(model, dataset)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# responseProcessing.process_model_responses_for_analysis()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mload_model_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_dataset\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModelNames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQwenInstruct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, DatasetNames\u001b[38;5;241m.\u001b[39mMGSM\n",
      "File \u001b[1;32me:\\Masters\\Rug\\Courses\\2a\\Advance NLP\\Project\\code\\IKNLP-Attribution\\attribution\\model_utils.py:14\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model_name)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, padding_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Keep the original model for regex generation\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Uncomment on resource constrained machines, leads to slower inference\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# quantization_config=BitsAndBytesConfig(load_in_8bit=True)\u001b[39;49;00m\n\u001b[0;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Create text generation pipeline with the same model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m     26\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:573\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    572\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    574\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    575\u001b[0m     )\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m )\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\transformers\\modeling_utils.py:272\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\transformers\\modeling_utils.py:4455\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4446\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   4448\u001b[0m     (\n\u001b[0;32m   4449\u001b[0m         model,\n\u001b[0;32m   4450\u001b[0m         missing_keys,\n\u001b[0;32m   4451\u001b[0m         unexpected_keys,\n\u001b[0;32m   4452\u001b[0m         mismatched_keys,\n\u001b[0;32m   4453\u001b[0m         offload_index,\n\u001b[0;32m   4454\u001b[0m         error_msgs,\n\u001b[1;32m-> 4455\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4461\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4465\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4472\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4475\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[0;32m   4476\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\transformers\\modeling_utils.py:4693\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, low_cpu_mem_usage, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, device_mesh, key_mapping, weights_only, _fast_init)\u001b[0m\n\u001b[0;32m   4690\u001b[0m     original_checkpoint_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(state_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m   4691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4692\u001b[0m     original_checkpoint_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m-> 4693\u001b[0m         \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   4694\u001b[0m     )\n\u001b[0;32m   4696\u001b[0m \u001b[38;5;66;03m# Check if we are in a special state, i.e. loading from a state dict coming from a different architecture\u001b[39;00m\n\u001b[0;32m   4697\u001b[0m prefix \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbase_model_prefix\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\transformers\\modeling_utils.py:564\u001b[0m, in \u001b[0;36mload_state_dict\u001b[1;34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[0m\n\u001b[0;32m    562\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m--> 564\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m str_to_torch_dtype[\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_dtype()]\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m map_location \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    566\u001b[0m         state_dict[k] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(size\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mget_slice(k)\u001b[38;5;241m.\u001b[39mget_shape(), dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if '__main__':\n",
    "    model, dataset = load_model_dataset()\n",
    "    \n",
    "    responseProcessing = ResponseProcessing(model, dataset)\n",
    "    responseProcessing.process_model_responses_for_analysis()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    " 1. read from \"analysis_{model_name}\"\n",
    " 2. pass in model_generated_steps and query\n",
    " 3. Check if there answer matches with our answer\n",
    " 4. If yes, then use cc.getattribution() to attribution [contextCite](https://github.com/MadryLab/context-cite)\n",
    " 5. Save the np.array to the respective row of the \"analysis_{model_name}\" set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "## step\n",
    "context = \"\"\"\n",
    "\" Step-by-Step Answer:\n",
    "1.  First, calculate the number of eggs laid by the ducks per day: 16 eggs/day.\n",
    "2.  Janet eats 3 eggs for breakfast every morning, so subtract those: 16 - 3 = 13 eggs remaining.\n",
    "3.  She also bakes muffins for her friends using 4 eggs, so again subtract those: 13 - 4 = 9 eggs remaining.\n",
    "4.  Janet sells these remaining eggs at the farmers' market for $2 per egg, so multiply the number of eggs by this price: 9 * $2 = $18 per day\"\n",
    "\"\"\"\n",
    "\n",
    "## model_generated_answer\n",
    "query = \"Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cc \u001b[38;5;241m=\u001b[39m \u001b[43mContextCiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\context_cite\\context_citer.py:147\u001b[0m, in \u001b[0;36mContextCiter.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, context, query, device, model_kwargs, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03mLoad a ContextCiter instance from a pretrained model.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m        tokenizer, context, query, and other keyword arguments.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    144\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    145\u001b[0m     pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[0;32m    146\u001b[0m )\n\u001b[1;32m--> 147\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    149\u001b[0m     pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs\n\u001b[0;32m    150\u001b[0m )\n\u001b[0;32m    151\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\transformers\\modeling_utils.py:3712\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3708\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3709\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3710\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3711\u001b[0m         )\n\u001b[1;32m-> 3712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1324\u001b[0m             device,\n\u001b[0;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1326\u001b[0m             non_blocking,\n\u001b[0;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1328\u001b[0m         )\n\u001b[1;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32me:\\kaggle_comps\\predict_future_sales\\code\\venv\\new-venv\\lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "cc = ContextCiter.from_pretrained(model_name, context, query, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyNewVenv",
   "language": "python",
   "name": "mynewvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
