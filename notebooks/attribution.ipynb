{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: outlines in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: interegular in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (3.1.2)\n",
      "Requirement already satisfied: lark in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (1.2.2)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (1.5.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (1.26.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from outlines) (3.1.0)\n",
      "Requirement already satisfied: diskcache in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (5.6.3)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from outlines) (2.10.4)\n",
      "Requirement already satisfied: referencing in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (0.32.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (4.20.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from outlines) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from outlines) (4.12.2)\n",
      "Requirement already satisfied: iso3166 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (2.1.1)\n",
      "Requirement already satisfied: airportsdata in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (20250224)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (2.6.0+cu124)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (0.1.26)\n",
      "Requirement already satisfied: genson in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (1.3.0)\n",
      "Requirement already satisfied: pre-commit>=4.0.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (4.2.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (2.6.9)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (6.0.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (20.29.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.0->outlines) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.0->outlines) (2.27.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jinja2->outlines) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jsonschema->outlines) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jsonschema->outlines) (2023.11.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jsonschema->outlines) (0.15.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests->outlines) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests->outlines) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests->outlines) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests->outlines) (2023.11.17)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->outlines) (3.18.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->outlines) (3.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->outlines) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch->outlines) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from sympy==1.13.1->torch->outlines) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from tqdm->outlines) (0.4.6)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (0.3.9)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (4.1.0)\n",
      "Collecting context_cite\n",
      "  Downloading context_cite-0.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (1.26.2)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from context_cite) (4.49.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (2.15.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (2.1.4)\n",
      "Collecting nltk>=3.8.2 (from context_cite)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting spacy (from context_cite)\n",
      "  Using cached spacy-3.8.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (1.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from context_cite) (4.67.1)\n",
      "Collecting click (from nltk>=3.8.2->context_cite)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from nltk>=3.8.2->context_cite) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from nltk>=3.8.2->context_cite) (2023.10.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (2.31.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->context_cite) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from datasets->context_cite) (0.29.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (6.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from tqdm->context_cite) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pandas->context_cite) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pandas->context_cite) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pandas->context_cite) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from scikit-learn->context_cite) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from scikit-learn->context_cite) (3.2.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->context_cite)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->context_cite)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->context_cite)\n",
      "  Using cached murmurhash-1.0.12-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->context_cite)\n",
      "  Using cached cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->context_cite)\n",
      "  Using cached preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy->context_cite)\n",
      "  Using cached thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->context_cite)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy->context_cite)\n",
      "  Using cached srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->context_cite)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy->context_cite)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy->context_cite)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from spacy->context_cite) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from spacy->context_cite) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from spacy->context_cite) (75.8.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy->context_cite)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->context_cite) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch->context_cite) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->context_cite) (3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch->context_cite) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from sympy==1.13.1->torch->context_cite) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers->context_cite) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers->context_cite) (0.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.3.1)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy->context_cite)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->context_cite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->context_cite) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->context_cite) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests>=2.19.0->datasets->context_cite) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests>=2.19.0->datasets->context_cite) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests>=2.19.0->datasets->context_cite) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests>=2.19.0->datasets->context_cite) (2023.11.17)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy->context_cite)\n",
      "  Using cached blis-1.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy->context_cite)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy->context_cite)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy->context_cite) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy->context_cite)\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy->context_cite)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jinja2->spacy->context_cite) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->context_cite)\n",
      "  Using cached marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (2.19.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->context_cite)\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (0.1.2)\n",
      "Downloading context_cite-0.0.4-py3-none-any.whl (13 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached spacy-3.8.4-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Using cached preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp311-cp311-win_amd64.whl (632 kB)\n",
      "Using cached thinc-8.3.4-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached blis-1.2.0-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "Downloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, click, catalogue, blis, srsly, smart-open, preshed, nltk, language-data, typer, langcodes, confection, weasel, thinc, spacy, context_cite\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 click-8.1.8 cloudpathlib-0.21.0 confection-0.1.5 context_cite-0.0.4 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 nltk-3.9.1 preshed-3.0.9 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install outlines\n",
    "!pip install context_cite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add the path to the parent directory to sys\n",
    "import sys, os\n",
    "\n",
    "# If current directory is called 'notebooks', chdir to the parent\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('../')\n",
    "    \n",
    "sys.path.append('attribution')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from constants import ModelNames, DatasetNames, LANGUAGE_MAPPING\n",
    "from model_utils import Model \n",
    "from dataset_utils import GSMDataset, PaddingCollator, is_correct_gsm, extract_answer_gsm\n",
    "from context_cite import ContextCiter\n",
    "from tqdm.notebook import tqdm\n",
    "from attribution.cleaning import ResponseProcessor\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Filter specific warning categories\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # For general user warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # For deprecation warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    " 1. read from \"analysis_{model_name}\"\n",
    " 2. pass in model_generated_steps and query\n",
    " 3. Check if there answer matches with our answer (I think it might be worthwile to also check wrong answers.)\n",
    " 4. If yes, then use cc.getattribution() to attribution [contextCite](https://github.com/MadryLab/context-cite)\n",
    " 5. Save the np.array to the respective row of the \"analysis_{model_name}\" set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>actual_answer</th>\n",
       "      <th>model_gen_steps</th>\n",
       "      <th>model_gen_answer</th>\n",
       "      <th>model_answer_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question : Roger a 5 balles de tennis. Il achè...</td>\n",
       "      <td>18</td>\n",
       "      <td>Step-by-Step Answer:\\n1  Janet pond 16 œufs pa...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>La réponse est 18.&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question : Roger a 5 balles de tennis. Il achè...</td>\n",
       "      <td>3</td>\n",
       "      <td>Step-by-Step Answer:\\n1  Une robe nécessite 2 ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>La réponse est 3.&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question : Roger a 5 balles de tennis. Il achè...</td>\n",
       "      <td>70000</td>\n",
       "      <td>Step-by-Step Answer:\\n1  Le prix initial de la...</td>\n",
       "      <td>195000.0</td>\n",
       "      <td>La réponse est 195000.&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Question : Roger a 5 balles de tennis. Il achè...</td>\n",
       "      <td>540</td>\n",
       "      <td>Step-by-Step Answer:\\n1  Jacques fait 3 sprint...</td>\n",
       "      <td>540.0</td>\n",
       "      <td>La réponse est 540.&lt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question : Roger a 5 balles de tennis. Il achè...</td>\n",
       "      <td>20</td>\n",
       "      <td>Step-by-Step Answer:\\n1  Wendi donne 15 bols d...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>La réponse est 20.&lt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  actual_answer  \\\n",
       "0  Question : Roger a 5 balles de tennis. Il achè...             18   \n",
       "1  Question : Roger a 5 balles de tennis. Il achè...              3   \n",
       "2  Question : Roger a 5 balles de tennis. Il achè...          70000   \n",
       "3  Question : Roger a 5 balles de tennis. Il achè...            540   \n",
       "4  Question : Roger a 5 balles de tennis. Il achè...             20   \n",
       "\n",
       "                                     model_gen_steps  model_gen_answer  \\\n",
       "0  Step-by-Step Answer:\\n1  Janet pond 16 œufs pa...              18.0   \n",
       "1  Step-by-Step Answer:\\n1  Une robe nécessite 2 ...               3.0   \n",
       "2  Step-by-Step Answer:\\n1  Le prix initial de la...          195000.0   \n",
       "3  Step-by-Step Answer:\\n1  Jacques fait 3 sprint...             540.0   \n",
       "4  Step-by-Step Answer:\\n1  Wendi donne 15 bols d...              20.0   \n",
       "\n",
       "          model_answer_str  \n",
       "0      La réponse est 18.<  \n",
       "1       La réponse est 3.<  \n",
       "2  La réponse est 195000.<  \n",
       "3     La réponse est 540.<  \n",
       "4      La réponse est 20.<  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_model = Model(ModelNames.QwenInstruct)\n",
    "\n",
    "# Unlike RAG, the context follows the query\n",
    "prompt_template = '{query}\\n{context}'\n",
    "\n",
    "model_responses = pd.read_csv(f'results/processed/mgsm_fr_COT_constrained_Qwen2.5-1.5B-Instruct_results.csv')\n",
    "model_responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf9884a5534480eb187b046c6a0920e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 0\n"
     ]
    }
   ],
   "source": [
    "cite_df = pd.DataFrame()\n",
    "\n",
    "# Get length of model_responses\n",
    "len_responses = len(model_responses)\n",
    "\n",
    "# initialize a progress bar\n",
    "pbar = tqdm(total=len_responses)\n",
    "error_counter = 0\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in model_responses.iterrows():\n",
    "    pbar.update(1)\n",
    "    context = row['model_gen_steps']\n",
    "    query = row['question']\n",
    "    answer_string = row['model_answer_str']\n",
    "    \n",
    "    # Abstain from pre-train because it creates a new model each time\n",
    "    # Constructor is needed due to processing during initialization\n",
    "    cc = ContextCiter(context_model.model, context_model.tokenizer, context, query, prompt_template=prompt_template)\n",
    "    \n",
    "    # We want to use precomputed answers\n",
    "    # See https://github.com/MadryLab/context-cite/issues/4\n",
    "    _, prompt = cc._get_prompt_ids(return_prompt=True)\n",
    "    cc._cache[\"output\"] = prompt + answer_string\n",
    "    \n",
    "    # This returns an importance for each line in the context\n",
    "    # The progress bar is annoying\n",
    "    line_importance = cc.get_attributions(as_dataframe=False, verbose=False)\n",
    "    \n",
    "    # Get each line and importance and add to df\n",
    "    lines = context.split('\\n')\n",
    "    \n",
    "    # If number of lines and importance values do not match, raise an error\n",
    "    if len(lines) != len(line_importance):\n",
    "        print(f\"Number of lines ({len(lines)}) and importance values ({len(line_importance)}) do not match in example {index} Skipping...\")\n",
    "        error_counter += 1\n",
    "        continue\n",
    "    \n",
    "    # Create a temporary DataFrame with sample_index to identify which example each line belongs to\n",
    "    temp_df = pd.DataFrame({\n",
    "        'sample_index': index,  # Use the DataFrame index as sample index\n",
    "        'line': lines,\n",
    "        'importance': line_importance\n",
    "    })\n",
    "    \n",
    "    cite_df = pd.concat([cite_df, temp_df], ignore_index=True)\n",
    "    \n",
    "pbar.close()\n",
    "print(f\"Number of errors: {error_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results as JSON\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Create a list to store one dictionary per question\n",
    "result_list = []\n",
    "\n",
    "# Custom JSON encoder to handle NumPy types\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.integer, np.int64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.floating, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super().default(obj)\n",
    "\n",
    "for sample_index, group in cite_df.groupby('sample_index'):\n",
    "    original_row = model_responses.iloc[sample_index]\n",
    "    \n",
    "    # Create a dictionary for this sample\n",
    "    sample_dict = {\n",
    "        'sample_index': sample_index,  # No need to manually convert\n",
    "        'question': original_row['question'],\n",
    "        'actual_answer': int(float(original_row['actual_answer'])),\n",
    "        'model_gen_answer': int(float(original_row['model_gen_answer'])),\n",
    "        'model_answer_str': original_row['model_answer_str'],\n",
    "        'lines_and_importance': [\n",
    "            {'text': row['line'], 'importance': row['importance']} \n",
    "            for _, row in group.iterrows()\n",
    "        ]  # No need to manually convert\n",
    "    }\n",
    "    \n",
    "    # Add this dictionary to our results list\n",
    "    result_list.append(sample_dict)\n",
    "\n",
    "# Save as JSON file with proper formatting and custom encoder\n",
    "with open('results/contextcite_fr_QwenInstruct_COT.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(result_list, f, ensure_ascii=False, indent=2, cls=NumpyEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
