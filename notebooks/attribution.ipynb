{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: outlines in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: interegular in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (3.1.2)\n",
      "Requirement already satisfied: lark in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (1.2.2)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (1.5.8)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (1.26.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from outlines) (3.1.0)\n",
      "Requirement already satisfied: diskcache in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (5.6.3)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from outlines) (2.10.4)\n",
      "Requirement already satisfied: referencing in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (0.32.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (4.20.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from outlines) (4.67.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from outlines) (4.12.2)\n",
      "Requirement already satisfied: iso3166 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (2.1.1)\n",
      "Requirement already satisfied: airportsdata in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (20250224)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (2.6.0+cu124)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (0.1.26)\n",
      "Requirement already satisfied: genson in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (1.3.0)\n",
      "Requirement already satisfied: pre-commit>=4.0.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from outlines) (4.2.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (2.6.9)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (6.0.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pre-commit>=4.0.1->outlines) (20.29.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.0->outlines) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic>=2.0->outlines) (2.27.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jinja2->outlines) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jsonschema->outlines) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jsonschema->outlines) (2023.11.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jsonschema->outlines) (0.15.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests->outlines) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests->outlines) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests->outlines) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests->outlines) (2023.11.17)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->outlines) (3.18.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->outlines) (3.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->outlines) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch->outlines) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from sympy==1.13.1->torch->outlines) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from tqdm->outlines) (0.4.6)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (0.3.9)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (4.1.0)\n",
      "Collecting context_cite\n",
      "  Downloading context_cite-0.0.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (1.26.2)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from context_cite) (4.49.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (2.15.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (2.1.4)\n",
      "Collecting nltk>=3.8.2 (from context_cite)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting spacy (from context_cite)\n",
      "  Using cached spacy-3.8.4-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from context_cite) (1.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from context_cite) (4.67.1)\n",
      "Collecting click (from nltk>=3.8.2->context_cite)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from nltk>=3.8.2->context_cite) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from nltk>=3.8.2->context_cite) (2023.10.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (2.31.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->context_cite) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from datasets->context_cite) (0.29.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from datasets->context_cite) (6.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from tqdm->context_cite) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pandas->context_cite) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pandas->context_cite) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from pandas->context_cite) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from scikit-learn->context_cite) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from scikit-learn->context_cite) (3.2.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->context_cite)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->context_cite)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->context_cite)\n",
      "  Using cached murmurhash-1.0.12-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->context_cite)\n",
      "  Using cached cymem-2.0.11-cp311-cp311-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->context_cite)\n",
      "  Using cached preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy->context_cite)\n",
      "  Using cached thinc-8.3.4-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->context_cite)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy->context_cite)\n",
      "  Using cached srsly-2.5.1-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->context_cite)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy->context_cite)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy->context_cite)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from spacy->context_cite) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from spacy->context_cite) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from spacy->context_cite) (75.8.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy->context_cite)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->context_cite) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch->context_cite) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from torch->context_cite) (3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from torch->context_cite) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from sympy==1.13.1->torch->context_cite) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers->context_cite) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers->context_cite) (0.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from aiohttp->datasets->context_cite) (1.3.1)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy->context_cite)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->context_cite) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->context_cite) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->context_cite) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests>=2.19.0->datasets->context_cite) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests>=2.19.0->datasets->context_cite) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests>=2.19.0->datasets->context_cite) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from requests>=2.19.0->datasets->context_cite) (2023.11.17)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy->context_cite)\n",
      "  Using cached blis-1.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy->context_cite)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy->context_cite)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from typer<1.0.0,>=0.3.0->spacy->context_cite) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy->context_cite)\n",
      "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy->context_cite)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\transformer\\lib\\site-packages (from jinja2->spacy->context_cite) (2.1.3)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->context_cite)\n",
      "  Using cached marisa_trie-1.2.1-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (2.19.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->context_cite)\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->context_cite) (0.1.2)\n",
      "Downloading context_cite-0.0.4-py3-none-any.whl (13 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached spacy-3.8.4-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Using cached preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp311-cp311-win_amd64.whl (632 kB)\n",
      "Using cached thinc-8.3.4-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached blis-1.2.0-cp311-cp311-win_amd64.whl (6.2 MB)\n",
      "Downloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached marisa_trie-1.2.1-cp311-cp311-win_amd64.whl (152 kB)\n",
      "Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, click, catalogue, blis, srsly, smart-open, preshed, nltk, language-data, typer, langcodes, confection, weasel, thinc, spacy, context_cite\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 click-8.1.8 cloudpathlib-0.21.0 confection-0.1.5 context_cite-0.0.4 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 nltk-3.9.1 preshed-3.0.9 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install outlines\n",
    "!pip install context_cite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add the path to the parent directory to sys\n",
    "import sys, os\n",
    "\n",
    "# If current directory is called 'notebooks', chdir to the parent\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('../')\n",
    "    \n",
    "sys.path.append('attribution')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from constants import ModelNames, DatasetNames, LANGUAGE_MAPPING\n",
    "from model_utils import Model \n",
    "from dataset_utils import GSMDataset, PaddingCollator, is_correct_gsm, extract_answer_gsm\n",
    "from context_cite import ContextCiter\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Filter specific warning categories\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  # For general user warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)  # For deprecation warnings\n",
    "\n",
    "# Definitions\n",
    "processed_data_path = \"results/analysis_mgsm_en_Qwen2.5-1.5B-Instruct_results.csv\"\n",
    "model_name = ModelNames.QwenInstruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Processing Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_dataset():\n",
    "    model = Model(ModelNames.QwenInstruct)\n",
    "    return model, DatasetNames.MGSM\n",
    "\n",
    "class ResponseProcessing():\n",
    "    def __init__(self, model, dataset):\n",
    "        self.df_column_names = [\"question\", \"actual_answer\", \"model_gen_steps\", \"model_gen_answer\" ]\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def convert_dashes_incremental_steps_list(self, steps):\n",
    "        furnished_steps = []\n",
    "\n",
    "        i = 1\n",
    "        for _, step in enumerate(steps[1:]):\n",
    "            if step:  # Skip empty parts (if any)\n",
    "                \n",
    "                # I removed the full stop because contextcite treats the step number itself as a new sentence\n",
    "                furnished_steps.append(str(i) + \" \" + step)  # Replace with number (1, 2, 3...)\n",
    "                i += 1\n",
    "        \n",
    "        return furnished_steps\n",
    "\n",
    "    def convert_dashes_incremental_steps(self, step):\n",
    "\n",
    "        '''\n",
    "        Returns str\n",
    "        '''\n",
    "\n",
    "        furnished_steps = self.convert_dashes_incremental_steps_list(step)\n",
    "\n",
    "        final_str = \"Step-by-Step Answer:\\n\"\n",
    "\n",
    "        # Added a \\n to better separate the steps\n",
    "        final_str += \"\\n\".join(furnished_steps)\n",
    "\n",
    "        return final_str\n",
    "\n",
    "\n",
    "    def process_model_responses_for_analysis(self):\n",
    "\n",
    "        mgsm_test = GSMDataset(self.dataset, self.model.tokenizer, instructions='', split='test', config='en')\n",
    "\n",
    "        mgsm_generation_df = pd.read_csv('results\\mgsm_en_Qwen2.5-1.5B-Instruct_results.csv')\n",
    "        mgsm_generations = mgsm_generation_df['response'].tolist()\n",
    "\n",
    "        all_steps = []\n",
    "        all_gen_final_ans = []\n",
    "\n",
    "        for response in mgsm_generations:\n",
    "            \n",
    "            steps = response.split(\"\\n-\")\n",
    "            final_step = steps[-1].split(\".\\r\\n\")[0]\n",
    "            steps.pop()\n",
    "            steps.append( final_step )\n",
    "\n",
    "            steps_str = self.convert_dashes_incremental_steps(steps)\n",
    "            all_steps.append( steps_str )\n",
    "\n",
    "            gen_final_ans = extract_answer_gsm(response)\n",
    "            all_gen_final_ans.append( gen_final_ans )\n",
    "\n",
    "        question_list = mgsm_test.dataset['question']\n",
    "        actual_answer = mgsm_test.dataset['answer_number']\n",
    "\n",
    "        percentile_list = pd.DataFrame(data=zip(question_list,actual_answer,all_steps, all_gen_final_ans), columns=self.df_column_names)\n",
    "\n",
    "        percentile_list.to_csv(processed_data_path, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# This will always be true. \n",
    "# I think you meant to use __name__ == '__main__' but this does not work in Jupyter Notebooks\n",
    "if '__main__':\n",
    "    context_model, dataset = load_model_dataset()\n",
    "    \n",
    "    responseProcessing = ResponseProcessing(context_model, dataset)\n",
    "    responseProcessing.process_model_responses_for_analysis()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    " 1. read from \"analysis_{model_name}\"\n",
    " 2. pass in model_generated_steps and query\n",
    " 3. Check if there answer matches with our answer\n",
    " 4. If yes, then use cc.getattribution() to attribution [contextCite](https://github.com/MadryLab/context-cite)\n",
    " 5. Save the np.array to the respective row of the \"analysis_{model_name}\" set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>actual_answer</th>\n",
       "      <th>model_gen_steps</th>\n",
       "      <th>model_gen_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>18</td>\n",
       "      <td>Step-by-Step Answer:\\n1  First, calculate the ...</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>3</td>\n",
       "      <td>Step-by-Step Answer:\\n1  The robe requires 2 b...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>70000</td>\n",
       "      <td>Step-by-Step Answer:\\n1  The original price of...</td>\n",
       "      <td>170000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>540</td>\n",
       "      <td>Step-by-Step Answer:\\n1  James runs 3 sprints ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>20</td>\n",
       "      <td>Step-by-Step Answer:\\n1  The total amount of f...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  actual_answer  \\\n",
       "0  Janet’s ducks lay 16 eggs per day. She eats th...             18   \n",
       "1  A robe takes 2 bolts of blue fiber and half th...              3   \n",
       "2  Josh decides to try flipping a house.  He buys...          70000   \n",
       "3  James decides to run 3 sprints 3 times a week....            540   \n",
       "4  Every day, Wendi feeds each of her chickens th...             20   \n",
       "\n",
       "                                     model_gen_steps  model_gen_answer  \n",
       "0  Step-by-Step Answer:\\n1  First, calculate the ...              18.0  \n",
       "1  Step-by-Step Answer:\\n1  The robe requires 2 b...               3.0  \n",
       "2  Step-by-Step Answer:\\n1  The original price of...          170000.0  \n",
       "3  Step-by-Step Answer:\\n1  James runs 3 sprints ...               3.0  \n",
       "4  Step-by-Step Answer:\\n1  The total amount of f...              20.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_model = Model(ModelNames.QwenInstruct)\n",
    "\n",
    "model_responses = pd.read_csv(processed_data_path)\n",
    "model_responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributed: To determine how much Janet makes from selling the eggs at the farmers' market each day, we need to follow these steps:\n",
      "\n",
      "1. Calculate the total number of eggs laid per day:\n",
      "   \\[\n",
      "   16 \\text{ eggs}\n",
      "   \\]\n",
      "\n",
      "2. Subtract the number of eggs Janet eats for breakfast each morning:\n",
      "   \\[\n",
      "   16 - 3 = 13 \\text{ eggs}\n",
      "   \\]\n",
      "\n",
      "3. Subtract the number of eggs used to bake muffins for her friends:\n",
      "   \\[\n",
      "   13 - 4 = 9 \\text{ eggs}\n",
      "   \\]\n",
      "\n",
      "4. Multiply the number of remaining eggs by the price per egg ($2):\n",
      "   \\[\n",
      "   9 \\times \\$2 = \\$18\n",
      "   \\]\n",
      "\n",
      "Therefore, Janet makes $18 per day at the farmers' market.<|im_end|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1587d857be47e1a370f1a6af764979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_75e6f_row0_col0 {\n",
       "  background-color: rgb(80, 180, 80);\n",
       "}\n",
       "#T_75e6f_row1_col0, #T_75e6f_row2_col0, #T_75e6f_row3_col0, #T_75e6f_row4_col0 {\n",
       "  background-color: rgb(255, 255, 255);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_75e6f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_75e6f_level0_col0\" class=\"col_heading level0 col0\" >Score</th>\n",
       "      <th id=\"T_75e6f_level0_col1\" class=\"col_heading level0 col1\" >Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_75e6f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_75e6f_row0_col0\" class=\"data row0 col0\" >7.314</td>\n",
       "      <td id=\"T_75e6f_row0_col1\" class=\"data row0 col1\" >4  Janet sells these remaining eggs at the farmers' market for $2 per egg, so multiply the number of eggs by this price: 9 * $2 = $18 per day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75e6f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_75e6f_row1_col0\" class=\"data row1 col0\" >0.000</td>\n",
       "      <td id=\"T_75e6f_row1_col1\" class=\"data row1 col1\" >The answer is 18.<</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75e6f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_75e6f_row2_col0\" class=\"data row2 col0\" >0.000</td>\n",
       "      <td id=\"T_75e6f_row2_col1\" class=\"data row2 col1\" >3  She also bakes muffins for her friends using 4 eggs, so again subtract those: 13 - 4 = 9 eggs remaining.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75e6f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_75e6f_row3_col0\" class=\"data row3 col0\" >0.000</td>\n",
       "      <td id=\"T_75e6f_row3_col1\" class=\"data row3 col1\" >2  Janet eats 3 eggs for breakfast every morning, so subtract those: 16 - 3 = 13 eggs remaining.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_75e6f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_75e6f_row4_col0\" class=\"data row4 col0\" >0.000</td>\n",
       "      <td id=\"T_75e6f_row4_col1\" class=\"data row4 col1\" >1  First, calculate the number of eggs laid by the ducks per day: 16 eggs/day.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fa07733cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in model_responses.iterrows():\n",
    "    context = row['model_gen_steps']\n",
    "    query = row['question']\n",
    "    \n",
    "    # Remove first line from context (The filler \"Step by Step\")\n",
    "    context = context.split(\"\\n\", 1)[1]\n",
    "    \n",
    "    # Abstain from pre-train because it creates a new model each time\n",
    "    # Contructor is needed due to processing during initialization\n",
    "    cc = ContextCiter(context_model.model, context_model.tokenizer, context, query)\n",
    "    df = cc.get_attributions(as_dataframe=True, verbose=True)\n",
    "    display(df)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
